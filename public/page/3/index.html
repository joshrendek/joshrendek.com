<!DOCTYPE html>
<html>

<head>
<meta charset="utf-8" />
<meta name="author" content="" />
<meta name="description" content="" />
<meta name="keywords" content="" />
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.25.1" />

<meta property="og:title" content="Josh Rendek" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://joshrendek.com/" />



<meta property="og:updated_time" content="2013-07-04T00:00:00&#43;00:00"/>













<meta itemprop="name" content="Josh Rendek">
<meta itemprop="description" content="">



<link rel="stylesheet" type="text/css" href="/css/layout.css" />
<link rel="stylesheet" type="text/css" href="/css/pygments.css" />
<link rel="stylesheet" type="text/css" href="/css/color-dark.css" />


<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-3754808-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>


<title>


    Josh Rendek

</title>

<script src="/js/highlight.min.js"></script>
<link rel="stylesheet" href="/css/tomorrow-night.min.css" />
<script>hljs.initHighlightingOnLoad();</script>

</head>


<body>
<div class="main">
<header>

<div class="header-bar">

  <nav>
    <div class="siteTitle">
      <a href="https://joshrendek.com">
        <span class='blue-brace'>{</span>
        Josh Rendek
        <span class='blue-brace'>}</span>
      </a>
      <div class="header-subtitle">
        <h2>
          <span class="heart">&lt;3</span> Ruby &amp; Go
        </h2>
      </div>
    </div> 
  </nav>
  <nav>
      
      
      <a class="nav-item active" href="/"><div class="nav-item-title">Home</div></a>
      
      <a class="nav-item" href="/projects/"><div class="nav-item-title">Projects</div></a>
      
      <a class="nav-item" href="/archives/"><div class="nav-item-title">Archives</div></a>
      
      <a class="nav-item" href="https://devopsbyvideo.com/"><div class="nav-item-title">Screen Casts</div></a>
      
      <a class="nav-item" href="/about/"><div class="nav-item-title">About</div></a>
      
      <a class="nav-item" href="/categories/"><div class="nav-item-title">Categories</div></a>
      
      <a class="nav-item" href="https://github.com/joshrendek/"><div class="nav-item-title">GitHub</div></a>
      
      <a class="nav-item" href="/resume.pdf"><div class="nav-item-title">Resume</div></a>
      
   </nav>
</div>

  
<div class="social-links-header">

  

  

  

  

  

</div>


</header>


<main>
  <div class="articles">
    
    
    <article class="post">
      <div class="date"> Jul 4, 2013 - 2 minutes</div>
      <h1 class="title"> <a href='https://joshrendek.com/2013/07/a-simple-ruby-plugin-system/'> A simple ruby plugin system</a> </h1>
      <div class="content"> <p>Let&rsquo;s start out with a simple directory structure:</p>

<pre><code class="language-bash">.
├── plugin.rb
├── main.rb
└── plugins
    ├── cat.rb
    └── dog.rb

1 directory, 3 files
</code></pre>

<p>All the plugins we will use for our library will be loaded from <code>plugins</code>. Now lets make a simple
<code>Plugin</code> class and register our plugins.</p>

<pre><code class="language-ruby">
class Plugin
  # Keep the plugin list inside a set so we don't double-load plugins
  @plugins = Set.new

  def self.plugins
    @plugins
  end

  def self.register_plugins
    # Iterate over each symbol in the object space
    Object.constants.each do |klass|
      # Get the constant from the Kernel using the symbol
      const = Kernel.const_get(klass)
      # Check if the plugin has a super class and if the type is Plugin
      if const.respond_to?(:superclass) and const.superclass == Plugin
        @plugins &lt;&lt; const
      end
    end
  end
end

</code></pre>

<p>We&rsquo;ve now made a simple class that will contain all of our plugin data when we call <code>register_plugins</code>.</p>

<p>Now for our Dog and Cat classes:</p>

<pre><code class="language-ruby">class DogPlugin &lt; Plugin

  def handle_command(cmd)
    p &quot;Command received #{cmd}&quot;
  end

end
</code></pre>

<pre><code class="language-ruby">class CatPlugin &lt; Plugin

  def handle_command(cmd)
    p &quot;Command received #{cmd}&quot;
  end

end
</code></pre>

<p>Now combine this all together in one main entry point and we have a simple plugin system that lets us
send messages to each plugin through a set method ( <code>handle_command</code> ).</p>

<pre><code class="language-ruby">
require './plugin'
Dir[&quot;./plugins/*.rb&quot;].each { |f| require f }
Plugin.register_plugins

# Test that we can send a message to each plugin
Plugin.plugins.each do |plugin|
  plugin.handle_command('test')
end

</code></pre>

<p>This is a very simple but useful way to make a plugin system to componentize projects like a chat bot for IRC.</p>
 </div>
    </article>
    
    <article class="post">
      <div class="date"> Feb 26, 2013 - 11 minutes</div>
      <h1 class="title"> <a href='https://joshrendek.com/2013/02/why-setuid-is-bad-and-what-you-can-do/'> Why setuid Is Bad and What You Can Do</a> </h1>
      <div class="content"> 

<h2 id="why-setuid-is-bad">Why <code>setuid</code> is Bad</h2>

<p><code>setuid</code> allows a binary to be run as a different user then the one invoking it. For example, ping needs to use low level system interfaces (<code>socket</code>, <code>PF_INET</code>, <code>SOCK_RAW</code>, etc) in order to function properly. We can watch this in action by starting ping in another terminal window ( <code>ping google.com</code> ) and then using <code>strace</code> to see the syscall&rsquo;s being made:</p>

<p><code>sudo strace -p PID</code> and we get the following:</p>

<pre><code class="language-bash">munmap(0x7f329e7ea000, 4096)            = 0stat(&quot;/etc/resolv.conf&quot;, {st_mode=S_IFREG|0644, st_size=185, ...}) = 0
socket(PF_INET, SOCK_DGRAM|SOCK_NONBLOCK, IPPROTO_IP) = 4
connect(4, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr(&quot;8.8.8.8&quot;)}, 16) = 0
</code></pre>

<p>We can find all setuid programs installed by issuing the command:</p>

<pre><code class="language-bash">sudo find / -xdev \( -perm -4000 \) -type f -print0 -exec ls -l {} \;
</code></pre>

<p>This will find all commands that have the root setuid bit set in their permission bit.</p>

<p><a name="top"></a></p>

<h4 id="setuid-list-for-a-few-popular-operating-systems"><code>setuid</code> list for a few popular operating systems:</h4>

<p>Of particular interest in OpenBSD, where a lot of work was done to remove and switch programs from needing to use setuid/gid permissions. OpenIndiana is the worst offender and has the widest vector for attack.</p>

<ul>
<li><a href="#ubuntu">Ubuntu</a> (22 binaries)</li>
<li><a href="#centos">CentOS</a> (21 binaries)</li>
<li><a href="#openbsd">OpenBSD</a> (3 binaries)</li>
<li><a href="#openindiana">OpenIndiana</a> (53 binaries)</li>
</ul>

<p><code>setuid</code> escalation is a common attack vector and can allow unprivileged code to be executed by a regular user, and then escalate itself to root and drop you in on the root shell.</p>

<p><strong><em>Here are a few examples:</em></strong></p>

<h4 id="cve-2012-0056-exploiting-proc-pid-mem">CVE-2012-0056: Exploiting /proc/pid/mem</h4>

<p><a href="http://blog.zx2c4.com/749">http://blog.zx2c4.com/749</a> - C code that uses a bug in the way the Linux kernel checked permissions on /proc/pid/mem and then uses that to exploit the su binary to give a root shell.</p>

<h4 id="cve-2010-3847-exploiting-via-origin-and-file-descriptors">CVE-2010-3847: Exploiting via $ORIGIN and file descriptors</h4>

<p><a href="http://www.exploit-db.com/exploits/15274/">http://www.exploit-db.com/exploits/15274/</a> - By exploiting a hole in the way the $ORIGIN is checked, a symlink can be made to a program that uses <code>setuid</code> and <code>exec</code>&rsquo;d &lsquo;to obtain the file descriptors which then lets arbitrary code injection (in this case a call to <code>system(&quot;/bin/bash&quot;)</code>).</p>

<p>More of these can be found at <a href="http://www.exploit-db.com/shellcode/">http://www.exploit-db.com/shellcode/</a> and just <a href="https://www.google.com/search?q=setuid+exploits">searching google for <code>setuid</code> exploits</a>.</p>

<p>So you may not want to completely disable the <code>setuid</code> flag on all the binaries for your distribution, but we can turn on some logging to watch when they&rsquo;re getting called and install a kernel patch that will secure the OS and help prevent 0-days that may prey on <code>setuid</code> vulnerabilities.</p>

<h2 id="how-to-log-setuid-calls">How to log setuid calls</h2>

<p>I will detail the steps to do this on Ubuntu, but they should apply to the other audit daemons on CentOS.</p>

<p>Let&rsquo;s first install auditd: <code>sudo apt-get install auditd</code></p>

<p>Let&rsquo;s open up <code>/etc/audit/audit.rules</code>, and with a few tweaks with vim, we can insert the list we generated with find into the audit rule set (explanation of each flag after the jump):</p>

<pre><code class="language-bash"># This file contains the auditctl rules that are loaded# whenever the audit daemon is started via the initscripts.
# The rules are simply the parameters that would be passed
# to auditctl.

# First rule - delete all
-D

# Increase the buffers to survive stress events.
# Make this bigger for busy systems
-b 320

# Feel free to add below this line. See auditctl man page

-a always,exit -F path=/usr/lib/pt_chown -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/lib/eject/dmcrypt-get-device -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/lib/dbus-1.0/dbus-daemon-launch-helper -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/lib/openssh/ssh-keysign -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/sbin/uuidd -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/sbin/pppd -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/bin/at -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/bin/passwd -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/bin/mtr -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/bin/sudoedit -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/bin/traceroute6.iputils -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/bin/chsh -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/bin/sudo -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/bin/chfn -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/bin/gpasswd -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/usr/bin/newgrp -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/bin/fusermount -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/bin/umount -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/bin/ping -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/bin/ping6 -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/bin/su -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
-a always,exit -F path=/bin/mount -F perm=x -F auid&gt;=500 -F auid!=4294967295 -k privileged
</code></pre>

<pre><code class="language-text">-a: appends the always, and exit rules. This says to always make a log at syscall entry and syscall exit.
-F
     path= says filter to the executable being called
     perm=x says filter on the program being executable
     auid&gt;= says log all calls for users who have a UID above 500 (regular user accounts start at 1000 generally)
     auid!=4294967295 sometimes a process may start before the auditd, in which case it will get a auid of 4294967295
-k passes a filter key that will be put into the record log, in this case its &quot;privileged&quot;
</code></pre>

<p>So now when we run ping google.com we can see a full audit trail in <code>/var/log/audit/audit.log</code>:</p>

<pre><code class="language-bash">type=SYSCALL msg=audit(1361852594.621:48): arch=c000003e syscall=59 success=yes exit=0 a0=f43de8 a1=d40488 a2=ed8008 a3=7fffc9c9a150 items=2 ppid=1464 pid=1631 auid=1000 uid=1000 gid=1000 euid=0 suid=0 fsuid=0 egid=1000 sgid=1000 fsgid=1000 tty=pts1 ses=6 comm=&quot;ping&quot; exe=&quot;/bin/ping&quot; key=&quot;privileged&quot;type=EXECVE msg=audit(1361852594.621:48): argc=2 a0=&quot;ping&quot; a1=&quot;google.com&quot;
type=BPRM_FCAPS msg=audit(1361852594.621:48): fver=0 fp=0000000000000000 fi=0000000000000000 fe=0 old_pp=0000000000000000 old_pi=0000000000000000 old_pe=0000000000000000 new_pp=ffffffffffffffff new_pi=0000000000000000 new_pe=ffffffffffffffff
type=CWD msg=audit(1361852594.621:48):  cwd=&quot;/home/ubuntu&quot;
type=PATH msg=audit(1361852594.621:48): item=0 name=&quot;/bin/ping&quot; inode=131711 dev=08:01 mode=0104755 ouid=0 ogid=0 rdev=00:00
type=PATH msg=audit(1361852594.621:48): item=1 name=(null) inode=934 dev=08:01 mode=0100755 ouid=0 ogid=0 rdev=00:00
</code></pre>

<h2 id="next-steps-patching-and-upgrading-the-kernel-with-grsecurity">Next steps: Patching and upgrading the kernel with GRSecurity</h2>

<p>GRSecurity is an awesome tool in the security-minded system administrators toolbag. It will prevent zero days (like the proc mem exploit explained above <a href="http://en.wikibooks.org/wiki/Grsecurity/Appendix/Grsecurity_and_PaX_Configuration_Options#Remove_addresses_from_.2Fproc.2F.3Cpid.3E.2F.5Bsmaps.7Cmaps.7Cstat.5D"><sup>1</sup></a> ) by securing which areas a user can access. A full list can be seen at <a href="http://en.wikibooks.org/wiki/Grsecurity/Appendix/Grsecurity_and_PaX_Configuration_Options">http://en.wikibooks.org/wiki/Grsecurity/Appendix/Grsecurity_and_PaX_Configuration_Options</a> and <a href="http://en.wikipedia.org/wiki/Grsecurity#Miscellaneous_features">http://en.wikipedia.org/wiki/Grsecurity#Miscellaneous_features</a>, I suggest going through these and seeing if you want to continue with this.</p>

<p><strong>The following below is for advanced users. Not responsible for any issues you may run into, please make sure to test this in a staging/test environment.</strong></p>

<p>Here are the steps I followed to install the patch:</p>

<pre><code class="language-bash"># Start by downloading the latest kernel
wget http://www.kernel.org/pub/linux/kernel/v3.0/linux-3.2.39.tar.bz2

# Next extract it
tar xjvf linux-3.2.39.tar.bz2
cd linux-3.2.39

# Copy over your current kernel configuration:
cp -vi /boot/config-`uname -r` .config

# Updates the config file to match old config and prompts for any new kernel options.
make oldconfig

# This will make sure only modules get compiled only if they are in your kernel.
make localmodconfig

# Bring up the configuration menu
make menuconfig
</code></pre>

<p>Once your in the menu config you can browse to the <code>Security</code> section and go to <code>Grsecurity</code> and enable it. I set the configuration method to automatic and then went to Customize. For example, you can now go to <code>Kernel Auditing -&gt; Exec logging</code> to turn on some additional logging to shell activities (<strong>WARNING: this will generate a lot of log activity, decide if you want to use this or not). I suggest going through all of these and reading through their menu help descriptions (when selecting one, press the <code>?</code> key to bring up the help</strong>).</p>

<p>Now we&rsquo;ll finish making the kernel and compiling it:</p>

<pre><code class="language-bash"># Now we can compile the kernel
make -j2 # where 2 is the # of CPU's + 1

# Install and load the dynamic kernel modules
sudo make modules_install

# Finally install kernel
sudo make install
</code></pre>

<p>We can now reboot and boot into our GRsecurity patched kernel!</p>

<p>Hopefully this article has provided some insight into what the <code>setuid</code> flag does, how it has and can be exploited, and what we can do to prevent this in the future.</p>

<p>Here are a few links to useful books on the subject of shellcode and exploits that I reccomend:</p>

<h3 id="below-is-the-list-of-setuid-binaries-on-each-os">Below is the list of <code>setuid</code> binaries on each OS</h3>

<p><a name="ubuntu"></a></p>

<h4 id="ubuntu-12-04-lts-22">Ubuntu 12.04 LTS (22)</h4>

<p><a href="#top">back to top</a></p>

<pre><code class="language-bash">-rwsr-xr-x 1 root    root        31304 Mar  2  2012 /bin/fusermount-rwsr-xr-x 1 root    root        94792 Mar 30  2012 /bin/mount
-rwsr-xr-x 1 root    root        35712 Nov  8  2011 /bin/ping
-rwsr-xr-x 1 root    root        40256 Nov  8  2011 /bin/ping6
-rwsr-xr-x 1 root    root        36832 Sep 12 18:29 /bin/su
-rwsr-xr-x 1 root    root        69096 Mar 30  2012 /bin/umount
-rwsr-sr-x 1 daemon  daemon      47928 Oct 25  2011 /usr/bin/at
-rwsr-xr-x 1 root    root        41832 Sep 12 18:29 /usr/bin/chfn
-rwsr-xr-x 1 root    root        37096 Sep 12 18:29 /usr/bin/chsh
-rwsr-xr-x 1 root    root        63848 Sep 12 18:29 /usr/bin/gpasswd
-rwsr-xr-x 1 root    root        62400 Jul 28  2011 /usr/bin/mtr
-rwsr-xr-x 1 root    root        32352 Sep 12 18:29 /usr/bin/newgrp
-rwsr-xr-x 1 root    root        42824 Sep 12 18:29 /usr/bin/passwd
-rwsr-xr-x 2 root    root        71288 May 31  2012 /usr/bin/sudo
-rwsr-xr-x 2 root    root        71288 May 31  2012 /usr/bin/sudoedit
-rwsr-xr-x 1 root    root        18912 Nov  8  2011 /usr/bin/traceroute6.iputils
-rwsr-xr-- 1 root    messagebus 292944 Oct  3 13:03 /usr/lib/dbus-1.0/dbus-daemon-launch-helper
-rwsr-xr-x 1 root    root        10408 Dec 13  2011 /usr/lib/eject/dmcrypt-get-device
-rwsr-xr-x 1 root    root       240984 Apr  2  2012 /usr/lib/openssh/ssh-keysign
-rwsr-xr-x 1 root    root        10592 Oct  5 16:08 /usr/lib/pt_chown
-rwsr-xr-- 1 root    dip        325744 Feb  4  2011 /usr/sbin/pppd
-rwsr-sr-x 1 libuuid libuuid     18856 Mar 30  2012 /usr/sbin/uuidd
</code></pre>

<p><a name="centos"></a></p>

<h4 id="centos-6-3-21">CentOS 6.3 (21)</h4>

<p><a href="#top">back to top</a></p>

<pre><code class="language-bash">-rwsr-xr-x. 1 root root  76056 Nov  5 05:21 /bin/mount-rwsr-xr-x. 1 root root  40760 Jul 19  2011 /bin/ping
-rwsr-xr-x. 1 root root  36488 Jul 19  2011 /bin/ping6
-rwsr-xr-x. 1 root root  34904 Jun 22  2012 /bin/su
-rwsr-xr-x. 1 root root  50496 Nov  5 05:21 /bin/umount
-rwsr-x---. 1 root dbus  46232 Sep 13 13:04 /lib64/dbus-1/dbus-daemon-launch-helper
-rwsr-xr-x. 1 root root  10272 Apr 16  2012 /sbin/pam_timestamp_check
-rwsr-xr-x. 1 root root  34840 Apr 16  2012 /sbin/unix_chkpwd
-rwsr-xr-x. 1 root root  54240 Jan 30  2012 /usr/bin/at
-rwsr-xr-x. 1 root root  66352 Dec  7  2011 /usr/bin/chage
-rws--x--x. 1 root root  20184 Nov  5 05:21 /usr/bin/chfn
-rws--x--x. 1 root root  20056 Nov  5 05:21 /usr/bin/chsh
-rwsr-xr-x. 1 root root  47520 Jul 19  2011 /usr/bin/crontab
-rwsr-xr-x. 1 root root  71480 Dec  7  2011 /usr/bin/gpasswd
-rwsr-xr-x. 1 root root  36144 Dec  7  2011 /usr/bin/newgrp
-rwsr-xr-x. 1 root root  30768 Feb 22  2012 /usr/bin/passwd
---s--x--x. 2 root root 219272 Aug  6  2012 /usr/bin/sudo
---s--x--x. 2 root root 219272 Aug  6  2012 /usr/bin/sudoedit
-rwsr-xr-x. 1 root root 224912 Nov  9 07:49 /usr/libexec/openssh/ssh-keysign
-rws--x--x. 1 root root  14280 Jan 31 06:30 /usr/libexec/pt_chown
-rwsr-xr-x. 1 root root   9000 Sep 17 05:55 /usr/sbin/usernetctl
</code></pre>

<p><a name="openbsd"></a></p>

<h4 id="openbsd-5-2-3">OpenBSD 5.2 (3)</h4>

<p><a href="#top">back to top</a></p>

<pre><code class="language-bash">-r-sr-xr-x  1 root  bin       242808 Aug  1  2012 /sbin/ping-r-sr-xr-x  1 root  bin       263288 Aug  1  2012 /sbin/ping6
-r-sr-x---  1 root  operator  222328 Aug  1  2012 /sbin/shutdown
</code></pre>

<p><a name="openindiana"></a></p>

<h4 id="openindiana-11-53">OpenIndiana 11 (53)</h4>

<p><a href="#top">back to top</a></p>

<pre><code class="language-bash">-rwsr-xr-x   1 root     bin        64232 Jun 30  2012 /sbin/wificonfig--wS--lr-x   1 root     root           0 Dec 11 15:20 /media/.hal-mtab-lock
-r-sr-xr-x   1 root     bin       206316 Dec 11 21:00 /usr/lib/ssh/ssh-keysign
-rwsr-xr-x   1 root     adm        12140 Jun 30  2012 /usr/lib/acct/accton
-r-sr-xr-x   1 root     bin        23200 Jun 30  2012 /usr/lib/fs/ufs/quota
-r-sr-xr-x   1 root     bin       111468 Jun 30  2012 /usr/lib/fs/ufs/ufsrestore
-r-sr-xr-x   1 root     bin       106964 Jun 30  2012 /usr/lib/fs/ufs/ufsdump
-r-sr-xr-x   1 root     bin        18032 Jun 30  2012 /usr/lib/fs/smbfs/umount
-r-sr-xr-x   1 root     bin        18956 Jun 30  2012 /usr/lib/fs/smbfs/mount
-r-sr-xr-x   1 root     bin        12896 Jun 30  2012 /usr/lib/utmp_update
-r-sr-xr-x   1 root     bin        35212 Jun 30  2012 /usr/bin/fdformat
-r-s--x--x   2 root     bin       188080 Jun 30  2012 /usr/bin/sudoedit
-r-sr-xr-x   1 root     sys        34876 Jun 30  2012 /usr/bin/su
-r-sr-xr-x   1 root     bin        42504 Jun 30  2012 /usr/bin/login
-r-sr-xr-x   1 root     bin       257288 Jun 30  2012 /usr/bin/pppd
-r-sr-xr-x   1 root     sys        46208 Jun 30  2012 /usr/bin/chkey
-r-sr-xr-x   1 root     sys        29528 Jun 30  2012 /usr/bin/amd64/newtask
-r-sr-xr-x   2 root     bin        24432 Jun 30  2012 /usr/bin/amd64/w
-r-sr-xr-x   1 root     bin      3224200 Jun 30  2012 /usr/bin/amd64/Xorg
-r-sr-xr-x   2 root     bin        24432 Jun 30  2012 /usr/bin/amd64/uptime
-rwsr-xr-x   1 root     sys        47804 Jun 30  2012 /usr/bin/at
-r-sr-xr-x   1 root     bin         8028 Jun 30  2012 /usr/bin/mailq
-r-sr-xr-x   1 root     bin        33496 Jun 30  2012 /usr/bin/rsh
-r-sr-xr-x   1 root     bin        68704 Jun 30  2012 /usr/bin/rmformat
-r-sr-sr-x   1 root     sys        31292 Jun 30  2012 /usr/bin/passwd
-rwsr-xr-x   1 root     sys        23328 Jun 30  2012 /usr/bin/atrm
-r-sr-xr-x   1 root     bin        97072 Jun 30  2012 /usr/bin/xlock
-r-sr-xr-x   1 root     bin        78672 Jun 30  2012 /usr/bin/rdist
-r-sr-xr-x   1 root     bin        27072 Jun 30  2012 /usr/bin/sys-suspend
-r-sr-xr-x   1 root     bin        29304 Jun 30  2012 /usr/bin/crontab
-r-sr-xr-x   1 root     bin        53080 Jun 30  2012 /usr/bin/rcp
-r-s--x--x   2 root     bin       188080 Jun 30  2012 /usr/bin/sudo
-r-s--x--x   1 uucp     bin        70624 Jun 30  2012 /usr/bin/tip
-rwsr-xr-x   1 root     sys        18824 Jun 30  2012 /usr/bin/atq
-r-sr-xr-x   1 root     bin       281732 Jun 30  2012 /usr/bin/xscreensaver
-r-sr-xr-x   1 root     bin      2767780 Jun 30  2012 /usr/bin/i86/Xorg
-r-sr-xr-x   1 root     sys        22716 Jun 30  2012 /usr/bin/i86/newtask
-r-sr-xr-x   2 root     bin        22020 Jun 30  2012 /usr/bin/i86/w
-r-sr-xr-x   2 root     bin        22020 Jun 30  2012 /usr/bin/i86/uptime
-rwsr-xr-x   1 root     sys        13636 Jun 30  2012 /usr/bin/newgrp
-r-sr-xr-x   1 root     bin        39224 Jun 30  2012 /usr/bin/rlogin
-rwsr-xr-x   1 svctag   daemon    108964 Jun 30  2012 /usr/bin/stclient
-r-sr-xr-x   1 root     bin        29324 Jun 30  2012 /usr/xpg4/bin/crontab
-rwsr-xr-x   1 root     sys        47912 Jun 30  2012 /usr/xpg4/bin/at
-r-sr-xr-x   3 root     bin        41276 Jun 30  2012 /usr/sbin/deallocate
-rwsr-xr-x   1 root     sys        32828 Jun 30  2012 /usr/sbin/sacadm
-r-sr-xr-x   1 root     bin        46512 Jun 30  2012 /usr/sbin/traceroute
-r-sr-xr-x   1 root     bin        18016 Jun 30  2012 /usr/sbin/i86/whodo
-r-sr-xr-x   1 root     bin        55584 Jun 30  2012 /usr/sbin/ping
-r-sr-xr-x   3 root     bin        41276 Jun 30  2012 /usr/sbin/allocate
-r-sr-xr-x   1 root     bin        37320 Jun 30  2012 /usr/sbin/pmconfig
-r-sr-xr-x   3 root     bin        41276 Jun 30  2012 /usr/sbin/list_devices
-r-sr-xr-x   1 root     bin        24520 Jun 30  2012 /usr/sbin/amd64/whodo
</code></pre>
 </div>
    </article>
    
    <article class="post">
      <div class="date"> Jan 17, 2013 - 10 minutes</div>
      <h1 class="title"> <a href='https://joshrendek.com/2013/01/securing-ubuntu/'> Securing Ubuntu</a> </h1>
      <div class="content"> 

<h2 id="table-of-contents">Table of Contents</h2>

<h4 id="initial-setup-initial-setup"><a href="#initial_setup">Initial Setup</a></h4>

<h4 id="setting-up-iptables-and-fail2ban-iptables-fail2ban"><a href="#iptables_fail2ban">Setting up iptables and Fail2Ban</a></h4>

<h5 id="span-style-padding-left-20px-span-fail2ban-fail2ban"><span style='padding-left: 20px;'></span><a href="#fail2ban">Fail2Ban</a></h5>

<h5 id="span-style-padding-left-20px-span-iptables-rules-iptables-rules"><span style='padding-left: 20px;'></span><a href="#iptables_rules">iptables rules</a></h5>

<h4 id="make-shared-memory-read-only-shared-memory"><a href="#shared_memory">Make shared memory read-only</a></h4>

<h4 id="setting-up-bastille-linux-bastille"><a href="#bastille">Setting up Bastille Linux</a></h4>

<h5 id="span-style-padding-left-20px-span-configuring-bastille-bastille-config"><span style='padding-left: 20px;'></span><a href="#bastille_config">Configuring Bastille</a></h5>

<h4 id="sysctl-hardening-sysctl"><a href="#sysctl">sysctl hardening</a></h4>

<h4 id="setting-up-a-chroot-environment-chroot"><a href="#chroot">Setting up a chroot environment</a></h4>

<h4 id="securing-nginx-inside-the-chroot-nginx"><a href="#nginx">Securing nginx inside the chroot</a></h4>

<h4 id="extras-extras"><a href="#extras">Extras</a></h4>

<p><a name="initial_setup"></a></p>

<h2 id="initial-setup">Initial Setup</h2>

<p>Let&rsquo;s login to our new machine and take some initial steps to secure our system. For this article I&rsquo;m going to assume your username is <code>ubuntu</code>.</p>

<p>If you need to, setup your sudoers file by adding the following lines to <code>/etc/sudoers</code>:</p>

<pre><code class="language-bash">ubuntu ALL=(ALL:ALL) ALL # put this in the &quot;User privilege specification&quot; section
</code></pre>

<p>Edit your <code>~/.ssh/authorized_keys</code> and put your public key inside it. Make sure you can login without a password now once your key is in place.</p>

<p>Open up <code>/etc/ssh/sshd_config</code> and make sure these lines exist to secure SSH:</p>

<pre><code class="language-bash"># Only allow version 2 communications, version 1 has known vulnerabilities
Protocol 2
# Disable root login over ssh
PermitRootLogin no
# Load authorized keys files from a users home directory
AuthorizedKeysFile  %h/.ssh/authorized_keys
# Don't allow empty passwords to be used to authenticate
PermitEmptyPasswords no
# Disable password auth, you must use ssh keys
PasswordAuthentication no
</code></pre>

<p>Keep your current session open and restart sshd:</p>

<pre><code>sudo service ssh restart
</code></pre>

<p>Make sure you can login from another terminal. If you can, move on.</p>

<p>Now we need to update and upgrade to make sure all of our packages are up to date and install two pre-requisites for later in the article: build-essential and ntp.</p>

<pre><code class="language-bash">sudo apt-get update
sudo apt-get install build-essential ntp
sudo apt-get upgrade
sudo reboot
</code></pre>

<p><a name="iptables_fail2ban"></a></p>

<h2 id="setting-up-iptables-and-fail2ban">Setting up iptables and Fail2Ban</h2>

<p><a name="fail2ban"></a></p>

<h3 id="fail2ban">Fail2Ban</h3>

<pre><code>sudo apt-get install fail2ban
</code></pre>

<p>Open up the fail2ban config and change the ban time, destemail, and maxretry <code>/etc/fail2ban/jail.conf</code>:</p>

<pre><code class="language-bash">[DEFAULT]
ignoreip = 127.0.0.1/8
bantime  = 3600
maxretry = 2
destemail = ubuntu@yourdomain.com
action = %(action_mw)s

[ssh]

enabled  = true
port     = ssh
filter   = sshd
logpath  = /var/log/auth.log
maxretry = 2
</code></pre>

<p>Now restart fail2ban.</p>

<pre><code>sudo service fail2ban restart
</code></pre>

<p>If you try and login from another machine and fail, you should see the ip in iptables.</p>

<pre><code># sudo iptables -L
Chain fail2ban-ssh (1 references)
target     prot opt source               destination
DROP       all  --  li203-XX.members.linode.com  anywhere
RETURN     all  --  anywhere             anywhere
</code></pre>

<p><a name="iptables_rules"></a></p>

<h3 id="iptables-rules">iptables Rules</h3>

<p>Here are my default iptables rules, it opens up port 80 and 443 for HTTP/HTTPS communication, and allows port 22.
We also allow ping and then log all denied calls and then reject everything else. If you have other services you need to run, such as a game server or something else, you&rsquo;ll have to add the rules to open up the ports in the iptables config.</p>

<p><code>/etc/iptables.up.rules</code></p>

<pre><code class="language-text">*filter

# Accepts all established inbound connections
 -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT

# Allows all outbound traffic
# You could modify this to only allow certain traffic
 -A OUTPUT -j ACCEPT

# Allows HTTP and HTTPS connections from anywhere (the normal ports for websites)
 -A INPUT -p tcp --dport 443 -j ACCEPT
 -A INPUT -p tcp --dport 80 -j ACCEPT
# Allows SSH connections for script kiddies
# THE -dport NUMBER IS THE SAME ONE YOU SET UP IN THE SSHD_CONFIG FILE
 -A INPUT -p tcp -m state --state NEW --dport 22 -j ACCEPT

# Now you should read up on iptables rules and consider whether ssh access
# for everyone is really desired. Most likely you will only allow access from certain IPs.

# Allow ping
 -A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT

# log iptables denied calls (access via 'dmesg' command)
 -A INPUT -m limit --limit 5/min -j LOG --log-prefix &quot;iptables denied: &quot; --log-level 7

# Reject all other inbound - default deny unless explicitly allowed policy:
 -A INPUT -j REJECT
 -A FORWARD -j REJECT

COMMIT
</code></pre>

<p>We can load that up into iptables:</p>

<pre><code class="language-bash">sudo iptables-restore &lt; /etc/iptables.up.rules
</code></pre>

<p>Make sure it loads on boot by putting it into the if-up scripts:
<code>/etc/network/if-up.d/iptables</code></p>

<pre><code class="language-bash">#!/bin/sh
iptables-restore /etc/iptables.up.rules
</code></pre>

<p>Now make it executable:</p>

<pre><code class="language-bash">chmod +x /etc/network/if-up.d/iptables
</code></pre>

<p>Rebooting here is optional, I usually reboot after major changes to make sure everything boots up properly.</p>

<p>If you&rsquo;re getting hit by scanners or brute-force attacks, you&rsquo;ll see a line similar to this in your <code>/var/log/syslog</code>:</p>

<pre><code>Jan 18 03:30:37 localhost kernel: [   79.631680] iptables denied: IN=eth0 OUT= MAC=04:01:01:40:70:01:00:12:f2:c6:e8:00:08:00 SRC=87.13.110.30 DST=192.34.XX.XX LEN=64 TOS=0x00 PREC=0x00 TTL=34 ID=57021 DF PROTO=TCP SPT=1253 DPT=135 WINDOW=53760 RES=0x00 SYN URGP=0
</code></pre>

<p><a name="shared_memory"></a></p>

<h2 id="read-only-shared-memory">Read only shared memory</h2>

<p>A common exploit vector is going through shared memory (which can let you change the UID of running programs and other malicious actions). It can also be used as a place to drop files once an initial breakin has been made. An example of one such exploit is available <a href="http://www.juniper.net/security/auto/vulnerabilities/vuln17587.html">here</a>.</p>

<p>Open <code>/etc/fstab/</code>:</p>

<pre><code class="language-bash">tmpfs     /dev/shm     tmpfs     defaults,ro     0     0
</code></pre>

<p>Once you do this you need to reboot.</p>

<p><a name="bastille"></a></p>

<h2 id="setting-up-bastille-linux">Setting up Bastille Linux</h2>

<blockquote>
<p>The Bastille Hardening program &ldquo;locks down&rdquo; an operating system, proactively configuring the system for increased security and decreasing its susceptibility to compromise. Bastille can also assess a system&rsquo;s current state of hardening, granularly reporting on each of the security settings with which it works.</p>
</blockquote>

<p><code>Bastille: Installation and Setup</code></p>

<pre><code class="language-bash">sudo apt-get install bastille # choose Internet site for postfix
# configure bastille
sudo bastille
</code></pre>

<p>After you run that command you&rsquo;ll be prompted to configure your system, here are the options I chose:</p>

<p><a name="bastille_config"></a></p>

<h3 id="configuring-bastille">Configuring Bastille</h3>

<ul>
<li>File permissions module: Yes (suid)</li>
<li>Disable SUID for mount/umount: Yes</li>
<li>Disable SUID on ping: Yes</li>
<li>Disable clear-text r-protocols that use IP-based authentication? Yes</li>
<li>Enforce password aging? No (situation dependent, I have no users accessing my machines except me, and I only allow ssh keys)</li>
<li>Default umask: Yes</li>
<li>Umask: 077</li>
<li>Disable root login on tty&rsquo;s 1-6: No</li>
<li>Password protect GRUB prompt: No (situation dependent, I&rsquo;m on a VPS and would like to get support in case I need it)</li>
<li>Password protect su mode: Yes</li>
<li>default-deny on tcp-wrappers and xinetd? No</li>
<li>Ensure telnet doesn&rsquo;t run? Yes</li>
<li>Ensure FTP does not run? Yes</li>
<li>display authorized use message? No (situation dependent, if you had other users, Yes)</li>
<li>Put limits on system resource usage? Yes</li>
<li>Restrict console access to group of users? Yes (then choose root)</li>
<li>Add additional logging? Yes</li>
<li>Setup remote logging if you have a remote log host, I don&rsquo;t so I answered No</li>
<li>Setup process accounting? Yes</li>
<li>Disable acpid? Yes</li>
<li>Deactivate nfs + samba? Yes (situation dependent)</li>
<li>Stop sendmail from running in daemon mode? No (I have this firewalled off, so I&rsquo;m not concerned)</li>
<li>Deactivate apache? Yes</li>
<li>Disable printing? Yes</li>
<li>TMPDIR/TMP scripts? No (if a multi-user system, yes)</li>
<li>Packet filtering script? No (we configured the firewall previously)</li>
<li>Finished? YES! &amp; reboot</li>
</ul>

<p>You can verify some of these changes by testing them out, for instance, the SUID change on ping:</p>

<p><code>Bastille: Verifying changes</code></p>

<pre><code class="language-bash">ubuntu@app1:~$ ping google.com
ping: icmp open socket: Operation not permitted
ubuntu@app1:~$ sudo ping google.com
PING google.com (74.125.228.72) 56(84) bytes of data.
64 bytes from iad23s07-in-f8.1e100.net (74.125.228.72): icmp_req=1 ttl=55 time=9.06 ms
^C
--- google.com ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 9.067/9.067/9.067/0.000 ms
</code></pre>

<p><a name="sysctl"></a></p>

<h2 id="sysctl-hardening">Sysctl hardening</h2>

<p>Since our machine isn&rsquo;t running as a router and is going to be running as an application/web server, there are additional
steps we can take to secure the machine. Many of these are from the NSA&rsquo;s security guide, which you can read in its entirety
<a href="http://www.nsa.gov/ia/_files/os/redhat/rhel5-guide-i731.pdf">here</a>.</p>

<p><code>/etc/sysctl.conf http://www.nsa.gov/ia/_files/os/redhat/rhel5-guide-i731.pdf Source</code></p>

<pre><code class="language-bash"># Protect ICMP attacks
net.ipv4.icmp_echo_ignore_broadcasts = 1

# Turn on protection for bad icmp error messages
net.ipv4.icmp_ignore_bogus_error_responses = 1

# Turn on syncookies for SYN flood attack protection
net.ipv4.tcp_syncookies = 1

# Log suspcicious packets, such as spoofed, source-routed, and redirect
net.ipv4.conf.all.log_martians = 1
net.ipv4.conf.default.log_martians = 1

# Disables these ipv4 features, not very legitimate uses
net.ipv4.conf.all.accept_source_route = 0
net.ipv4.conf.default.accept_source_route = 0

# Enables RFC-reccomended source validation (dont use on a router)
net.ipv4.conf.all.rp_filter = 1
net.ipv4.conf.default.rp_filter = 1

# Make sure no one can alter the routing tables
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.default.accept_redirects = 0
net.ipv4.conf.all.secure_redirects = 0
net.ipv4.conf.default.secure_redirects = 0

# Host only (we're not a router)
net.ipv4.ip_forward = 0
net.ipv4.conf.all.send_redirects = 0
net.ipv4.conf.default.send_redirects = 0


# Turn on execshild
kernel.exec-shield = 1
kernel.randomize_va_space = 1

# Tune IPv6
net.ipv6.conf.default.router_solicitations = 0
net.ipv6.conf.default.accept_ra_rtr_pref = 0
net.ipv6.conf.default.accept_ra_pinfo = 0
net.ipv6.conf.default.accept_ra_defrtr = 0
net.ipv6.conf.default.autoconf = 0
net.ipv6.conf.default.dad_transmits = 0
net.ipv6.conf.default.max_addresses = 1

# Optimization for port usefor LBs
# Increase system file descriptor limit
fs.file-max = 65535

# Allow for more PIDs (to reduce rollover problems); may break some programs 32768
kernel.pid_max = 65536

# Increase system IP port limits
net.ipv4.ip_local_port_range = 2000 65000

# Increase TCP max buffer size setable using setsockopt()
net.ipv4.tcp_rmem = 4096 87380 8388608
net.ipv4.tcp_wmem = 4096 87380 8388608

# Increase Linux auto tuning TCP buffer limits
# min, default, and max number of bytes to use
# set max to at least 4MB, or higher if you use very high BDP paths
net.core.rmem_max = 8388608
net.core.wmem_max = 8388608
net.core.netdev_max_backlog = 5000
net.ipv4.tcp_window_scaling = 1
</code></pre>

<p>After making these changes you should reboot.</p>

<p><a name="chroot"></a></p>

<h2 id="setting-up-a-chroot-environment">Setting up a chroot environment</h2>

<p>We&rsquo;ll be setting up a chroot environment to run our web server and applications in. Chroot&rsquo;s provide isolation from the rest of the operating system, so even in the event of a application compromise, damage can be mitigated.</p>

<p><code>chroot: Installation and Setup</code></p>

<pre><code class="language-bash">sudo apt-get install debootstrap dchroot
</code></pre>

<p>Now add this to your <code>/etc/schroot/schroot.conf</code> file, precise is the release of Ubuntu I&rsquo;m using, so change it if you need to:</p>

<p><code>/etc/schroot/schroot.conf</code></p>

<pre><code class="language-bash">[precise]
description=Ubuntu Precise LTS
location=/var/chroot
priority=3
users=ubuntu
groups=sbuild
root-groups=root
</code></pre>

<p>Now bootstrap the chroot with a minimal Ubuntu installation:</p>

<pre><code class="language-bash">sudo debootstrap --variant=buildd --arch amd64 precise /var/chroot/ http://mirror.anl.gov/pub/ubuntu/
sudo cp /etc/resolv.conf /var/chroot/etc/resolv.conf
sudo mount -o bind /proc /var/chroot/proc
sudo chroot /var/chroot/
apt-get install ubuntu-minimal
apt-get update

</code></pre>

<p>Add the following to <code>/etc/apt/sources.list</code> inside the chroot:</p>

<pre><code class="language-bash">deb http://archive.ubuntu.com/ubuntu precise main
deb http://archive.ubuntu.com/ubuntu precise-updates main
deb http://security.ubuntu.com/ubuntu precise-security main
deb http://archive.ubuntu.com/ubuntu precise universe
deb http://archive.ubuntu.com/ubuntu precise-updates universe
</code></pre>

<p>Let&rsquo;s test out our chroot and install nginx inside of it:</p>

<pre><code class="language-bash">apt-get update
apt-get install nginx
</code></pre>

<p><a name="nginx"></a></p>

<h2 id="securing-nginx-inside-the-chroot">Securing nginx inside the chroot</h2>

<p>First thing we will do is add a www user for nginx to run under:
<code>Adding a application user</code></p>

<pre><code class="language-bash">sudo chroot /var/chroot
useradd www -d /home/www
mkdir /home/www
chown -R www.www /home/www
</code></pre>

<p>Open up <code>/etc/nginx/nginx.conf</code> and make sure you change user to www inside the chroot:</p>

<pre><code class="language-bash">user www;
</code></pre>

<p>We can now start nginx inside the chroot:</p>

<pre><code class="language-bash">sudo chroot /var/chroot
service nginx start
</code></pre>

<p>Now if you go to <a href="http://your_vm_ip/">http://your_vm_ip/</a> you should see &ldquo;Welcome to nginx!&rdquo; running inside your fancy new chroot.</p>

<p>We also need to setup ssh to run inside the chroot so we can deploy our applications more easily.</p>

<p><code>Chroot: sshd</code></p>

<pre><code class="language-bash">sudo chroot /var/chroot
apt-get install openssh-server udev
</code></pre>

<p>Since we already have SSH for the main host running on 22, we&rsquo;re going to run SSH for the chroot on port 2222. We&rsquo;ll copy over our config from outside the chroot to the chroot.</p>

<p><code>sshd config</code></p>

<pre><code class="language-bash">sudo cp /etc/ssh/sshd_config /var/chroot/etc/ssh/sshd_config
</code></pre>

<p>Now open the config and change the bind port to 2222.</p>

<p>We also need to add the rules to our firewall script:
<code>/etc/iptables.up.rules</code></p>

<pre><code class="language-bash"># Chroot ssh
 -A INPUT -p tcp -m state --state NEW --dport 2222 -j ACCEPT
</code></pre>

<p>Now make a startup script for chroot-precise in <code>/etc/init.d/chroot-precise:
</code>/etc/init.d/chroot-precise`</p>

<pre><code class="language-bash">mount -o bind /proc /var/chroot/proc
mount -o bind /dev /var/chroot/dev
mount -o bind /sys /var/chroot/sys
mount -o bind /dev/pts /var/chroot/dev/pts
chroot /var/chroot service nginx start
chroot /var/chroot service ssh start
</code></pre>

<p>Set it to executable and to start at boot:</p>

<pre><code class="language-bash">sudo chmod +x /etc/init.d/chroot-precise
sudo update-rc.d chroot-precise defaults
</code></pre>

<p>Next is to put your public key inside the <code>.ssh/authorized_keys</code> file for the www user inside the chroot so you can ssh and deploy your applications.</p>

<p>If you want, you can test your server and reboot it now to ensure nginx and ssh boot up properly. If it&rsquo;s not running right now, you start it: <code>sudo /etc/init.d/chroot-precise</code>.</p>

<p>You should now be able to ssh into your chroot and main server without a password.</p>

<p><a name="extras"></a></p>

<h2 id="extras">Extras</h2>

<p>I would like to also mention the <a href="http://grsecurity.net/">GRSecurity kernel patch</a>. I had tried several times to install this (two different versions were released while I was writing this) and both make the kernel unable to compile. Hopefully they&rsquo;ll fix these bugs and I&rsquo;ll be able to update this article with notes on setting GRSecurity up as well.</p>

<p>I hope this article proved useful to anyone trying to secure a Ubuntu system, and if you liked it please share it!</p>
 </div>
    </article>
    
    <article class="post">
      <div class="date"> Dec 25, 2012 - 1 minutes</div>
      <h1 class="title"> <a href='https://joshrendek.com/2012/12/rb-rfo-status-simple-system-status-page-in-ruby/'> Rb RFO Status: A Simple System Status Page in Ruby</a> </h1>
      <div class="content"> 

<p><em>Rb RFO Status</em> is a simple system to post status updates to your team or customers in a easy to understand format so there is no delay in reporting a reason for outage.
It is modeled slightly after the <a href="http://status.heroku.com/">Heroku Status Page</a>.</p>

<p><strong>Source</strong>: <a href="https://github.com/bluescripts/rb_rfo_status">https://github.com/bluescripts/rb_rfo_status</a></p>

<p><strong>Download</strong>: <a href="https://s3.amazonaws.com/josh-opensource/rb_rfo_status-0.1.war">https://s3.amazonaws.com/josh-opensource/rb_rfo_status-0.1.war</a></p>

<p>It is licensed under the <em>MIT License</em> so do whatever you want with it!</p>

<p>I&rsquo;ve already opened up a few issues on Github that are enhancements, but this serves as a super simple application to deploy to keep your customers and team informed of system states.</p>

<h2 id="installation">Installation</h2>

<p>Download the .war file and deploy it in your favorite container (Tomcat, etc). Once the war file is extracted you can modify the config settings and start it.</p>

<p>To run migrations on an extracted WAR file:</p>

<pre><code>cd rb_rfo_status/WEB-INF
sudo RAILS_ENV=production BUNDLE_WITHOUT=development:test BUNDLE_GEMFILE=Gemfile GEM_HOME=gems java -cp lib/jruby-core-1.7.1.jar:lib/jruby-stdlib-1.7.1.jar:lib/gems-gems-activerecord-jdbc-adapter-1.2.2.1-lib-arjdbc-jdbc-adapter_java.jar:lib/gems-gems-jdbc-mysql-5.1.13-lib-mysql-connector-java-5.1.13.jar org.jruby.Main -S rake db:migrate
</code></pre>

<h2 id="screenshots">Screenshots</h2>

<h3 id="homepage">Homepage</h3>


<figure >
    
        <img src="https://www.evernote.com/shard/s4/sh/dd1aa9b9-cfcf-4257-af11-3d17d3f1e8dd/c7917a5540f04a60eacad189479e799c/res/6a125eeb-21c8-4f96-9ced-21169a89c527/skitch.png" />
    
    
</figure>


<h3 id="creating-an-incident">Creating an Incident</h3>


<figure >
    
        <img src="https://www.evernote.com/shard/s4/sh/29176e2c-d770-4c6d-a593-369786d9079d/4c564af13979ba3d5e272c836cc830a2/res/bd810786-94fc-4652-86e1-27885f12bad8/skitch.png?resizeSmall&amp;width=832" />
    
    
</figure>


<h3 id="updating-an-incident">Updating an incident</h3>


<figure >
    
        <img src="https://www.evernote.com/shard/s4/sh/84afb640-b46c-40eb-9b30-00583685b7a5/915d77b53e7755498e1ef98a86c1ee57/res/8eabf163-959c-4f31-bf88-cbeb6d97dc77/skitch.png?resizeSmall&amp;width=832" />
    
    
</figure>


<h3 id="a-resolved-incident">A resolved incident</h3>


<figure >
    
        <img src="https://www.evernote.com/shard/s4/sh/d0449a09-75e1-47bc-8bc9-7073b76bfdaa/7c68e52c97dc1b912c408f9f0c5bded0/res/b077981e-37e0-4e2b-a8e4-abc1ae092033/skitch.png?resizeSmall&amp;width=832" />
    
    
</figure>

 </div>
    </article>
    
    <article class="post">
      <div class="date"> Dec 5, 2012 - 2 minutes</div>
      <h1 class="title"> <a href='https://joshrendek.com/2012/12/dealing-with-cascading-failures-with-chef-server/'> Dealing with cascading failures with Chef Server</a> </h1>
      <div class="content"> <p><a href="http://www.opscode.com/">Chef</a> is awesome. Being able to recreate your entire environment from a recipe is an inredibly powerful tool, and I had started using Chef a few months ago. When I had initially configured the Chef server I hadn&rsquo;t paid much attention to the couchdb portion of it until I had a chef-server hiccup. Here are a few things to watch out for when running chef-server:</p>

<ul>
<li>Setup CouchDB <a href="http://wiki.apache.org/couchdb/Compaction">compaction</a> - Chef had a CouchDB size of 30+GB (after compaction it was only a few megabytes).</li>
<li>When resizing instances, make sure you setup RabbitMQ to use a <a href="http://www.rabbitmq.com/configure.html">NODENAME</a>. If you don&rsquo;t you&rsquo;ll run into an issue with RabbitMQ losing the database&rsquo;s that were setup (by default, they&rsquo;re based on hostname&hellip; so if you resize a EC2 instance the hostname may change, and you&rsquo;ll either have to do some moving around or manually set the NODENAME to the previous hostname).</li>
<li>Client&rsquo;s may fail to validate after this - requiring a regeneration of the validation.pem, which is fine since this file is only used for the initial bootstrap of a server.</li>
<li>Make sure you run your chef recipes you setup (for instance monitoring) on your chef-server.</li>
</ul>

<p>I hope these tips will be helpful to other people when they run into a Chef/CouchDB/RabbitMQ issue after a server resize or hostname change. Another really helpful place is #chef on freenode&rsquo;s IRC servers.</p>
 </div>
    </article>
    
    <article class="post">
      <div class="date"> Nov 3, 2012 - 10 minutes</div>
      <h1 class="title"> <a href='https://joshrendek.com/2012/11/sidekiq-vs-resque/'> Sidekiq vs Resque, with MRI and JRuby</a> </h1>
      <div class="content"> 

<p>Before we dive into the benchmarks of Resque vs Sidekiq it will first help to have a better understanding of how forking and threading works in Ruby.</p>

<h1 id="threading-vs-forking">Threading vs Forking</h1>

<h2 id="forking">Forking</h2>

<p>When you fork a process you are creating an entire copy of that process: the address space and all open file descriptors. You get a separate copy of the address space of the parent process, isolating any work done to that fork. If the forked child process does a lot of work and uses a lot of memory, when that child exits the memory gets free&rsquo;d back to the operating system. If your programming language (MRI Ruby) doesn&rsquo;t support actual kernel level threading, then this is the only way to spread work out across multiple cores since each process will get scheduled to a different core. You also gain some stability since if a child crashes the parent can just respawn a new fork, however there is a caveat. If the parent dies while there are children that haven&rsquo;t exited, then those children become zombies.</p>

<h3 id="forking-and-ruby">Forking and Ruby</h3>

<p>One important note about forking with Ruby is that the maintainers have done a good job on keeping memory usage down when forking. Ruby implements a copy on write system for memory allocation with child forks.</p>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span></span><span class="lineno"> 1 </span><span class="nb">require</span> <span class="s1">&#39;benchmark&#39;</span>
<span class="lineno"> 2 </span>
<span class="lineno"> 3 </span><span class="n">fork_pids</span> <span class="o">=</span> <span class="o">[]</span>
<span class="lineno"> 4 </span>
<span class="lineno"> 5 </span><span class="c1"># Lets fill up some memory</span>
<span class="lineno"> 6 </span>
<span class="lineno"> 7 </span><span class="n">objs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="lineno"> 8 </span><span class="n">objs</span><span class="o">[</span><span class="s1">&#39;test&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="o">[]</span>
<span class="lineno"> 9 </span><span class="mi">1_000_000</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
<span class="lineno">10 </span>  <span class="n">objs</span><span class="o">[</span><span class="s1">&#39;test&#39;</span><span class="o">]</span> <span class="o">&lt;&lt;</span> <span class="no">Object</span><span class="o">.</span><span class="n">new</span>
<span class="lineno">11 </span><span class="k">end</span>
<span class="lineno">12 </span>
<span class="lineno">13 </span>
<span class="lineno">14 </span>
<span class="lineno">15 </span><span class="mi">50</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
<span class="lineno">16 </span>    <span class="n">fork_pids</span> <span class="o">&lt;&lt;</span> <span class="no">Process</span><span class="o">.</span><span class="n">fork</span> <span class="k">do</span>
<span class="lineno">17 </span>        <span class="nb">sleep</span> <span class="mi">0</span><span class="o">.</span><span class="mi">1</span>
<span class="lineno">18 </span>    <span class="k">end</span>
<span class="lineno">19 </span><span class="k">end</span>
<span class="lineno">20 </span><span class="n">fork_pids</span><span class="o">.</span><span class="n">map</span><span class="p">{</span><span class="o">|</span><span class="nb">p</span><span class="o">|</span> <span class="no">Process</span><span class="o">.</span><span class="n">waitpid</span><span class="p">(</span><span class="nb">p</span><span class="p">)</span> <span class="p">}</span>
<span class="lineno">21 </span><span class="p">}</span>
</code></pre></div>


<p>We can see this in action here:</p>


<figure >
    
        <img src="/images/showdown/copy_on_write.png" />
    
    
</figure>


<p>However when we start modifying memory inside the child forks, memory quickly grows.</p>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span></span><span class="lineno">1 </span><span class="mi">50</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
<span class="lineno">2 </span>    <span class="n">fork_pids</span> <span class="o">&lt;&lt;</span> <span class="no">Process</span><span class="o">.</span><span class="n">fork</span> <span class="k">do</span>
<span class="lineno">3 </span>      <span class="mi">1_000_000</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
<span class="lineno">4 </span>        <span class="n">objs</span> <span class="o">&lt;&lt;</span> <span class="no">Object</span><span class="o">.</span><span class="n">new</span>
<span class="lineno">5 </span>      <span class="k">end</span>
<span class="lineno">6 </span>    <span class="k">end</span>
<span class="lineno">7 </span><span class="k">end</span>
<span class="lineno">8 </span><span class="n">fork_pids</span><span class="o">.</span><span class="n">map</span><span class="p">{</span><span class="o">|</span><span class="nb">p</span><span class="o">|</span> <span class="no">Process</span><span class="o">.</span><span class="n">waitpid</span><span class="p">(</span><span class="nb">p</span><span class="p">)</span> <span class="p">}</span>
</code></pre></div>


<p>We&rsquo;re now creating a million new objects in each forked child:</p>


<figure >
    
        <img src="/images/showdown/forced_copy_on_write.png" />
    
    
</figure>


<h2 id="threading">Threading</h2>

<p>Threads on the other hand have considerably less overhead since they share address space, memory, and allow easier communication (versus inter-process communication with forks). Context switching between threads inside the same process is also generally cheaper than scheduling switches between processes. Depending on the runtime being used, any issues that might occur using threads (for instance needing to use lots of memory for a task) can be handled by the garbage collector for the most part. One of the benefits of threading is that you do not have to worry about zombie processes since all threads die when the process dies, avoiding the issue of zombies.</p>

<h2 id="threading-with-ruby">Threading with Ruby</h2>

<p>As of 1.9 the GIL (Global Interpreter Lock) is gone! But it&rsquo;s only been renamed to the GVL (Global VM Lock). The GVL in MRI ruby uses a lock called <code>rb_thread_lock_t</code> which is a mutex around when ruby code can be run. When no ruby objects are being touched, you can actually run ruby threads in parallel before the GVL kicks in again (ie: system level blocking call, IO blocking outside of ruby). After these blocking calls each thread checks the interrupt <code>RUBY_VM_CHECK_INTS</code>.</p>

<p>With MRI ruby threads are pre-emptively scheduled using a function called <code>rb_thread_schedule</code> which schedules an &ldquo;interrupt&rdquo; that lets each thread get a fair amount of execution time (every 10 microseconds). <a href="http://svn.ruby-lang.org/cgi-bin/viewvc.cgi/trunk/thread.c?view=markup">[source: thread.c:1018]</a></p>

<p>We can see an example of the GIL/GVL in action here:</p>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span></span><span class="lineno"> 1 </span><span class="n">threads</span> <span class="o">=</span> <span class="o">[]</span>
<span class="lineno"> 2 </span>
<span class="lineno"> 3 </span><span class="n">objs</span> <span class="o">=</span> <span class="o">[]</span>
<span class="lineno"> 4 </span><span class="n">objs</span><span class="o">[</span><span class="s1">&#39;test&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="o">[]</span>
<span class="lineno"> 5 </span><span class="mi">1_000_000</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
<span class="lineno"> 6 </span>  <span class="n">objs</span> <span class="o">&lt;&lt;</span> <span class="no">Object</span><span class="o">.</span><span class="n">new</span>
<span class="lineno"> 7 </span><span class="k">end</span>
<span class="lineno"> 8 </span>
<span class="lineno"> 9 </span><span class="mi">50</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span> <span class="o">|</span><span class="n">num</span><span class="o">|</span>
<span class="lineno">10 </span>  <span class="n">threads</span> <span class="o">&lt;&lt;</span> <span class="no">Thread</span><span class="o">.</span><span class="n">new</span> <span class="k">do</span>
<span class="lineno">11 </span>    <span class="mi">1_000_000</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
<span class="lineno">12 </span>      <span class="n">objs</span> <span class="o">&lt;&lt;</span> <span class="no">Object</span><span class="o">.</span><span class="n">new</span>
<span class="lineno">13 </span>    <span class="k">end</span>
<span class="lineno">14 </span>  <span class="k">end</span>
<span class="lineno">15 </span><span class="k">end</span>
<span class="lineno">16 </span>
<span class="lineno">17 </span><span class="n">threads</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:join</span><span class="p">)</span>
</code></pre></div>


<p>Normally this would be an unsafe operation, but since the GIL/GVL exists we don&rsquo;t have to worry about two threads adding to the same ruby object at once since only one thread can run on the VM at once and it ends up being an atomic operation <em>(although don&rsquo;t rely on this quirk for thread safety, it definitely doesn&rsquo;t apply to any other VMs)</em>.</p>

<p>Another important note is that the Ruby GC is doing a really horrible job during this benchmark.</p>


<figure >
    
        <img src="/images/showdown/threading_leak.png" />
    
    
</figure>


<p>The memory kept growing so I had to kill the process after a few seconds.</p>

<h2 id="threading-with-jruby-on-the-jvm">Threading with JRuby on the JVM</h2>

<p>JRuby specifies the use of native threads based on the operating system support using the <code>getNativeThread</code> call <a href="https://github.com/jruby/jruby/blob/master/src/org/jruby/RubyThread.java#L216">[2]</a>. JRuby&rsquo;s implementation of threads using the JVM means there is no GIL/GVL. This allows CPU bound processes to utilize all cores of a machine without having to deal with forking (which, in the case of resque, can be <em>very</em> expensive).</p>

<p>When trying to execute the GIL safe code above JRuby spits out a concurrency error: <code>ConcurrencyError: Detected invalid array contents due to unsynchronized modifications with concurrent users</code></p>

<p>We can either add a mutex around this code or modify it to not worry about concurrent access. I chose the latter:</p>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span></span><span class="lineno"> 1 </span><span class="n">threads</span> <span class="o">=</span> <span class="o">[]</span>
<span class="lineno"> 2 </span>
<span class="lineno"> 3 </span><span class="n">objs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="lineno"> 4 </span><span class="n">objs</span><span class="o">[</span><span class="s1">&#39;test&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="o">[]</span>
<span class="lineno"> 5 </span><span class="mi">1_000_000</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
<span class="lineno"> 6 </span>  <span class="n">objs</span><span class="o">[</span><span class="s1">&#39;test&#39;</span><span class="o">]</span> <span class="o">&lt;&lt;</span> <span class="no">Object</span><span class="o">.</span><span class="n">new</span>
<span class="lineno"> 7 </span><span class="k">end</span>
<span class="lineno"> 8 </span>
<span class="lineno"> 9 </span><span class="mi">50</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span> <span class="o">|</span><span class="n">num</span><span class="o">|</span>
<span class="lineno">10 </span>  <span class="n">threads</span> <span class="o">&lt;&lt;</span> <span class="no">Thread</span><span class="o">.</span><span class="n">new</span> <span class="k">do</span>
<span class="lineno">11 </span>    <span class="mi">1_000_000</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
<span class="lineno">12 </span>      <span class="n">objs</span><span class="o">[</span><span class="n">num</span><span class="o">]</span> <span class="o">=</span> <span class="o">[]</span> <span class="k">if</span> <span class="n">objs</span><span class="o">[</span><span class="n">num</span><span class="o">].</span><span class="n">nil?</span>
<span class="lineno">13 </span>      <span class="n">objs</span><span class="o">[</span><span class="n">num</span><span class="o">]</span> <span class="o">&lt;&lt;</span> <span class="no">Object</span><span class="o">.</span><span class="n">new</span>
<span class="lineno">14 </span>    <span class="k">end</span>
<span class="lineno">15 </span>  <span class="k">end</span>
<span class="lineno">16 </span><span class="k">end</span>
<span class="lineno">17 </span>
<span class="lineno">18 </span><span class="n">threads</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:join</span><span class="p">)</span>
</code></pre></div>


<p>Compared to the MRI version, ruby running on the JVM was able to make some optimizations and keep memory usage around 800MB for the duration of the test:</p>


<figure >
    
        <img src="/images/showdown/jvm_threading.png" />
    
    
</figure>


<p>Now that we have a better understanding of the differences between forking and threading in Ruby, lets move on to Sidekiq and Resque.</p>

<h1 id="sidekiq-and-resque">Sidekiq and Resque</h1>

<h2 id="resque-s-view-of-the-world">Resque&rsquo;s view of the world</h2>

<p>Resque assumes chaos in your environment. It follows the forking model with C and ruby and makes a complete copy of each resque parent when a new job needs to be run. This has its advantages in preventing memory leaks, long running workers, and locking. You run into an issue with forking though when you need to increase the amount of workers on a machine. You end up not having enough spare CPU cycles since the majority are being taken up handling all the forking.</p>

<p>Resque follows a simple fork and do work model, each worker will take a job off the queue and fork a new process to do the job.</p>

<p><a href="https://github.com/defunkt/resque">Resque @ Github</a></p>

<h2 id="sidekiq-s-view-of-the-world">Sidekiq&rsquo;s view of the world</h2>

<p>Unlike Resque, Sidekiq uses threads and is extremely easy to use as a drop in replacement to Resque since they both work on the same <code>perform</code> method. When you dig into the results below you can see that Sidekiq&rsquo;s claim of being able to handle a larger number of workers and amount of work is true. Due to using threads and not having to allocate a new stack and address space for each fork, you get that overhead back and are able to do more work with a threaded model.</p>

<p>Sidekiq follows the actor pattern. So compared to Resque which has N workers that fork, Sidekiq has an Actor manager, with N threads and one Fetcher actor which will pop jobs off Redis and hand them to the Manager. Sidekiq handles the &ldquo;chaos&rdquo; portion of Resque by catching all exceptions and bubbling them up to an exception handler such as Airbrake or Errbit.</p>

<p>Now that we know how Sidekiq and Resque work we can get on to testing them and comparing the results.</p>

<p><a href="https://github.com/mperham/sideki://github.com/mperham/sidekiq">Sidekiq @ Github</a></p>

<h1 id="the-test-code">The Test Code</h1>

<p>The idea behind the test was to pick a CPU bound processing task, in this case SHA256 and apply it across a set of 20 numbers, 150,000 times.</p>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span></span><span class="lineno"> 1 </span><span class="nb">require</span> <span class="s1">&#39;sidekiq&#39;</span>
<span class="lineno"> 2 </span><span class="nb">require</span> <span class="s1">&#39;resque&#39;</span>
<span class="lineno"> 3 </span><span class="nb">require</span> <span class="s1">&#39;digest&#39;</span>
<span class="lineno"> 4 </span>
<span class="lineno"> 5 </span>
<span class="lineno"> 6 </span><span class="c1"># Running:</span>
<span class="lineno"> 7 </span><span class="c1"># sidekiq -r ./por.rb -c 240</span>
<span class="lineno"> 8 </span><span class="c1">#</span>
<span class="lineno"> 9 </span><span class="c1"># require &#39;sidekiq&#39;</span>
<span class="lineno">10 </span><span class="c1"># require &#39;./por&#39;</span>
<span class="lineno">11 </span><span class="c1"># queueing: 150_000.times { Sidekiq::Client.enqueue(POR, [rand(123098)]*20) }</span>
<span class="lineno">12 </span><span class="c1"># queueing: 150_000.times { Resque.enqueue(POR, [rand(123098)]*20) }</span>
<span class="lineno">13 </span>
<span class="lineno">14 </span><span class="k">class</span> <span class="nc">POR</span>
<span class="lineno">15 </span>  <span class="kp">include</span> <span class="no">Sidekiq</span><span class="o">::</span><span class="no">Worker</span>
<span class="lineno">16 </span>
<span class="lineno">17 </span>  <span class="vi">@queue</span> <span class="o">=</span> <span class="ss">:por</span>
<span class="lineno">18 </span>
<span class="lineno">19 </span>  <span class="k">def</span> <span class="nf">perform</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
<span class="lineno">20 </span>    <span class="n">arr</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">a</span><span class="o">|</span>
<span class="lineno">21 </span>      <span class="no">Digest</span><span class="o">::</span><span class="no">SHA2</span><span class="o">.</span><span class="n">new</span> <span class="o">&lt;&lt;</span> <span class="n">a</span><span class="o">.</span><span class="n">to_s</span>
<span class="lineno">22 </span>    <span class="k">end</span>
<span class="lineno">23 </span>  <span class="k">end</span>
<span class="lineno">24 </span>
<span class="lineno">25 </span>  <span class="k">def</span> <span class="nc">self</span><span class="o">.</span><span class="nf">perform</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
<span class="lineno">26 </span>    <span class="n">arr</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">a</span><span class="o">|</span>
<span class="lineno">27 </span>      <span class="no">Digest</span><span class="o">::</span><span class="no">SHA2</span><span class="o">.</span><span class="n">new</span> <span class="o">&lt;&lt;</span> <span class="n">a</span><span class="o">.</span><span class="n">to_s</span>
<span class="lineno">28 </span>    <span class="k">end</span>
<span class="lineno">29 </span>  <span class="k">end</span>
<span class="lineno">30 </span>
<span class="lineno">31 </span><span class="k">end</span>
</code></pre></div>


<h1 id="test-machine">Test Machine</h1>

<pre><code>      Model Name: Mac Pro
      Model Identifier: MacPro4,1
      Processor Name: Quad-Core Intel Xeon
      Processor Speed: 2.26 GHz
      Number of Processors: 2
      Total Number of Cores: 8
      L2 Cache (per Core): 256 KB
      L3 Cache (per Processor): 8 MB
      Memory: 12 GB
      Processor Interconnect Speed: 5.86 GT/s
</code></pre>

<p>This gives us a total of 16 cores to use for our testing. I&rsquo;m also using a <a href="http://www.amazon.com/gp/product/B004W2JKZI/ref=as_li_qf_sp_asin_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B004W2JKZI&amp;linkCode=as2&amp;tag=josren-20">Crucial M4 SSD</a></p>

<h1 id="results">Results</h1>

<h2 id="time-to-process-150-000-sets-of-20-numbers">Time to Process 150,000 sets of 20 numbers</h2>


<figure >
    
        <img src="/images/showdown/time_to_process.png" />
    
    
</figure>


<p><center>
<table width="100%" style="text-align: center;">
<tr>
<td><strong>Type</strong></td><td><strong>Time to Completion (seconds)</strong></td>
</tr>
<tr>
<td>Sidekiq (JRuby) 150 Threads</td><td>88</td>
</tr>
<tr>
<td>Sidekiq (JRuby) 240 Threads</td><td>89</td>
</tr>
<tr>
<td>Sidekiq (JRuby) 50 Threads</td><td>91</td>
</tr>
<tr>
<td>Sidekiq (MRI) 5x50</td><td>98</td>
</tr>
<tr>
<td>Sidekiq (MRI) 3x50</td><td>120</td>
</tr>
<tr>
<td>Sidekiq (MRI) 50</td><td>312</td>
</tr>
<tr>
<td>Resque 50</td><td>396</td>
</tr>
</table>
</center></p>

<hr>

<h2 id="all-about-the-cpu">All about the CPU</h2>

<h3 id="resque-50-workers">Resque: 50 workers</h3>


<figure >
    
        <img src="/images/showdown/resque_50.png" />
    
    
</figure>


<p>Here we can see that the forking is taking its toll on the available CPU we have for processing. Roughly 50% of the CPU is being wasted on forking and scheduling those new processes. Resque took 396 seconds to finish and process 150,000 jobs.</p>

<h3 id="sidekiq-mri-1-process-50-threads">Sidekiq (MRI) 1 process, 50 threads</h3>


<figure >
    
        <img src="/images/showdown/mri_50.png" />
    
    
</figure>


<p>We&rsquo;re not fully utilizing the CPU. When running this test it pegged one CPU at 100% usage and kept it there for the duration of the test. We have a slight overhead with system CPU usage. Sidekiq took 312 seconds with 50 threads using MRI Ruby. Lets now take a look at doing things a bit resque-ish, and use multiple sidekiq processes to get more threads scheduled across multiple CPUs.</p>

<h3 id="sidekiq-mri-3-processes-50-threads">Sidekiq (MRI) 3 processes, 50 threads</h3>


<figure >
    
        <img src="/images/showdown/mri_3x50.png" />
    
    
</figure>


<p>We&rsquo;re doing better. We&rsquo;ve cut our processing time roughly in third and we&rsquo;re utilizing more of our resources (CPUs). 3 Sidekiq processes with 50 threads each (for a total of 150 threads) took 120 seconds to complete 150,000 jobs.</p>

<h3 id="sidekiq-mri-5-processes-50-threads">Sidekiq (MRI) 5 processes, 50 threads</h3>


<figure >
    
        <img src="/images/showdown/mri_5x50.png" />
    
    
</figure>


<p>As we keep adding more processes that get scheduled to different cores we&rsquo;re seeing the CPU usage go up even further, however with more processes comes more overhead for process scheduling (versus thread scheduling). We&rsquo;re still wasting CPU cycles, but we&rsquo;re completing 150,000 jobs in 98 seconds.</p>

<h3 id="sidekiq-jruby-50-threads">Sidekiq (JRuby) 50 threads</h3>


<figure >
    
        <img src="/images/showdown/jruby_50.png" />
    
    
</figure>


<p>We&rsquo;re doing much better now with native threads. With 50 OS level threads, we&rsquo;re completing our set of jobs in 91 seconds.</p>

<h3 id="sidekiq-jruby-150-threads-240-threads">Sidekiq (JRuby) 150 threads &amp; 240 Threads</h3>

<p>
<figure >
    
        <img src="/images/showdown/jruby_150.png" />
    
    
</figure>


<figure >
    
        <img src="/images/showdown/jruby_240.png" />
    
    
</figure>
</p>

<p>We&rsquo;re no longer seeing a increase in (much) CPU usage and only a slight decrease in processing time. As we keep adding more and more threads we end up running into some thread contention issues with accessing redis and how quickly we can pop things off the queue.</p>

<h1 id="overview">Overview</h1>

<p>Even if we stick with the stock MRI ruby and go with Sidekiq, we&rsquo;re going to see a huge decrease in CPU usage while also gaining a little bit of performance as well.</p>

<p>Sidekiq, overall, provides a cleaner, more object oriented interface (in my opinion) to inspecting jobs and what is going on in the processing queue.</p>

<p>In Resque you would do something like: <code>Resque.size(&quot;queue_name&quot;)</code>. However, in Sidekiq you would take your class, in this case, <code>POR</code> and call <code>POR.jobs</code> to get the list of jobs for that worker queue. (note: you need to <code>require 'sidekiq/testing'</code> to get access to the jobs method).</p>

<p>The only thing I find missing from Sidekiq that I enjoyed in Resque was the ability to inspect failed jobs in the web UI. However Sidekiq more than makes up for that with the ability to automatically retry failed jobs (although be careful you don&rsquo;t introduce race conditions and accidentally DOS yourself).</p>

<p>And of course, JRuby comes out on top and gives us the best performance and bang for the buck (although your mileage may vary, depending on the task).</p>

<h1 id="further-reading">Further Reading</h1>

<p><a href="http://www.amazon.com/gp/product/1934356972/ref=as_li_qf_sp_asin_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1934356972&linkCode=as2&tag=josren-20">Deploying with JRuby: Deliver Scalable Web Apps using the JVM (Pragmatic Programmers)</a><img src="http://www.assoc-amazon.com/e/ir?t=josren-20&l=as2&o=1&a=1934356972" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /></p>

<p><a href="http://www.amazon.com/gp/product/B005SNJF28/ref=as_li_qf_sp_asin_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=B005SNJF28&linkCode=as2&tag=josren-20">JRuby Cookbook</a><img src="http://www.assoc-amazon.com/e/ir?t=josren-20&l=as2&o=1&a=B005SNJF28" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /></p>

<h1 id="sidekiq-resque">Sidekiq &amp; Resque</h1>

<p><a href="https://github.com/mperham/sidekiq">Sidekiq</a></p>

<p><a href="https://github.com/defunkt/resque">Resque</a></p>
 </div>
    </article>
    
    <article class="post">
      <div class="date"> Aug 28, 2012 - 1 minutes</div>
      <h1 class="title"> <a href='https://joshrendek.com/2012/08/preventing-a-ruby-class-from-being-reopened/'> Preventing a ruby class from being reopened</a> </h1>
      <div class="content"> <p>I saw the question of &ldquo;How can I prevent a class from being reopened again in Ruby?&rdquo; pop up on the Ruby mailing list. While this is somewhat against the nature of ruby, it can be accomplished:</p>

<p>{% codeblock lang:ruby %}
class Foo
  def Foo.method_added(name)
    raise &ldquo;This class is closed for modification&rdquo;
  end
end</p>

<p>class Foo
  def testing
    p &ldquo;test&rdquo;
  end
end
{% endcodeblock %}</p>

<p>This will raise an exception anytime someone tries to reopen the class.</p>
 </div>
    </article>
    
    <article class="post">
      <div class="date"> Aug 20, 2012 - 7 minutes</div>
      <h1 class="title"> <a href='https://joshrendek.com/2012/08/writing-dependable-ruby-and-a-reddit-cli/'> Writing Dependable Ruby &amp; a Reddit CLI</a> </h1>
      <div class="content"> 

<p><center>
    <a href="https://github.com/bluescripts/reddit-cli">View Source on Github</a>
</center></p>

<p>When you work on your code and are finished for the day, is what you have committed worry free? If another developer were to push your code in the middle of the night, would they be calling you at 3am?</p>

<p>Let&rsquo;s see how we can improve our development cycle with testing so we can avoid those early morning calls. We&rsquo;ll go over some of the basics with a simple project to start.</p>

<p>The most important part about TDD is getting quick feedback based on our desired design (the feedback loop).</p>

<p>Here is an example of how fast the tests run:
<object width="640" height="480"><param name="movie" value="http://www.youtube.com/v/GFQMT246FOg?version=3&amp;hl=en_US&hd=1"></param><param name="allowFullScreen" value="true"></param><param name="allowscriptaccess" value="always"></param><embed src="http://www.youtube.com/v/GFQMT246FOg?version=3&amp;hl=en_US&hd=1" type="application/x-shockwave-flash" width="640" height="480" allowscriptaccess="always" allowfullscreen="true"></embed></object></p>

<p>While this is a somewhat contrived example for the reddit cli we&rsquo;re making, this can be applied equally as well when writing Rails applications. Only load the parts you need (ActionMailer, ActiveSupport, etc), usually you don&rsquo;t need to load the entire rails stack. This can make your tests run in milliseconds instead of seconds. This lets you get feedback right away.</p>

<p>Before we go further into the testing discussion, lets setup a spec helper.</p>

<p>{% codeblock spec/spec_helper.rb lang:ruby %}
require &lsquo;rspec&rsquo;
require &lsquo;vcr&rsquo;
require &lsquo;pry&rsquo;
VCR.configure do |c|
  c.cassette_library_dir = &lsquo;fixtures/vcr_cassettes&rsquo;
  c.hook_into :fakeweb# or :fakeweb
end
{% endcodeblock %}</p>

<p>Now how do we start doing TDD? We first start with a failing test.</p>

<p>{% codeblock Reddit API Spec (Pass 1) - spec/lib/reddit_api_spec lang:ruby %}
require &lsquo;spec_helper&rsquo;
require &lsquo;./lib/reddit_api&rsquo;</p>

<p>describe RedditApi do
    let(:reddit) { RedditApi.new(&lsquo;ProgrammerHumor&rsquo;) }
    context &ldquo;#initializing&rdquo; do
        it &ldquo;should form the correct endpoint&rdquo; do
            reddit.url.should eq &ldquo;<a href="http://reddit.com/r/ProgrammerHumor/.json?after=&quot;">http://reddit.com/r/ProgrammerHumor/.json?after=&quot;</a>
        end
    end
end
{% endcodeblock %}</p>

<p>When we create a new instance of the Reddit API we want to pass it a subreddit, and then we want to make sure it builds the URL properly.</p>

<p>{% codeblock Reddit API (Pass 1) - lib/reddit_api.rb lang:ruby %}
require &lsquo;json&rsquo;
require &lsquo;rest-client&rsquo;</p>

<p>class RedditApi
    REDDIT_URL = &ldquo;<a href="http://reddit.com/r/&quot;">http://reddit.com/r/&quot;</a>
    attr_reader :url, :stories
    def initialize(subreddit)
        @subreddit = subreddit
        @after = &ldquo;&rdquo;
        @url = &ldquo;#{REDDIT_URL}#{subreddit}/.json?after=#{@after}&rdquo;
    end
end
{% endcodeblock %}</p>

<p>Next we want to make the actual HTTP request to the Reddit api and process it.</p>

<p>{% codeblock Reddit API Spec (Pass 2) - spec/lib/reddit_api_spec lang:ruby %}
require &lsquo;spec_helper&rsquo;
require &lsquo;./lib/reddit_api&rsquo;</p>

<p>describe RedditApi do
    let(:reddit) { RedditApi.new(&lsquo;ProgrammerHumor&rsquo;) }
    context &ldquo;#initializing&rdquo; do
        it &ldquo;should form the correct endpoint&rdquo; do
            VCR.use_cassette(&lsquo;reddit_programmer_humor&rsquo;) do
                reddit.url.should eq &ldquo;<a href="http://reddit.com/r/ProgrammerHumor/.json?after=&quot;">http://reddit.com/r/ProgrammerHumor/.json?after=&quot;</a>
            end
        end
    end</p>

<pre><code>context &quot;#fetching&quot; do
    it &quot;should fetch the first page of stories&quot; do
        VCR.use_cassette('reddit_programmer_humor') do
            reddit.stories.count.should eq(25)
        end
    end
end
</code></pre>

<p>end
{% endcodeblock %}</p>

<p>We&rsquo;ve now added a VCR wrapper and added an expectation that the reddit api will return a list of stories. We use VCR here to again ensure that our tests run fast. Once we make the first request, future runs will take milliseconds and will hit our VCR tape instead of the API.</p>

<p>Now we need to introduce three new areas: requesting, processing, and a Story object class.</p>

<p>{% codeblock Story - lib/story.rb lang:ruby %}
Story = Struct.new(:title, :score, :comments, :url)
{% endcodeblock %}</p>

<p>{% codeblock Reddit API (Pass 2) - lib/reddit_api.rb lang:ruby %}
require &lsquo;json&rsquo;
require &lsquo;rest-client&rsquo;
require &lsquo;./lib/story&rsquo;</p>

<p>class RedditApi
    REDDIT_URL = &ldquo;<a href="http://reddit.com/r/&quot;">http://reddit.com/r/&quot;</a>
    attr_reader :url, :stories
    def initialize(subreddit)
        @subreddit = subreddit
        @after = &ldquo;&rdquo;
        @url = &ldquo;#{REDDIT_URL}#{subreddit}/.json?after=#{@after}&rdquo;
        request
        process_request
    end</p>

<pre><code>def request
    @request_response = JSON.parse(RestClient.get(@url))
end

def process_request
    @stories = []
    @request_response['data']['children'].each do |red|
        d = red['data']
        @stories &lt;&lt; Story.new(d['title'], d['score'],
                              d['num_comments'], d['url'])
    end
    @after = @request_response['data']['after']
end
</code></pre>

<p>end
{% endcodeblock %}</p>

<p>What can we do now? The API lets us make a full request and get a list of Story struct objects back. We&rsquo;ll be using this array of structs later on to build the CLi.</p>

<p>The only thing left for this simple CLI a way to get to the next page. Let&rsquo;s add our failing spec:</p>

<p>{% codeblock Reddit API Spec (Pass 3) - spec/lib/reddit_api_spec lang:ruby %}
require &lsquo;spec_helper&rsquo;
require &lsquo;./lib/reddit_api&rsquo;</p>

<p>describe RedditApi do
    let(:reddit) { RedditApi.new(&lsquo;ProgrammerHumor&rsquo;) }
    context &ldquo;#initializing&rdquo; do
        it &ldquo;should form the correct endpoint&rdquo; do
            VCR.use_cassette(&lsquo;reddit_programmer_humor&rsquo;) do
                reddit.url.should eq &ldquo;<a href="http://reddit.com/r/ProgrammerHumor/.json?after=&quot;">http://reddit.com/r/ProgrammerHumor/.json?after=&quot;</a>
            end
        end
    end</p>

<pre><code>context &quot;#fetching&quot; do
    it &quot;should fetch the first page of stories&quot; do
        VCR.use_cassette('reddit_programmer_humor') do
            reddit.stories.count.should eq(25)
        end
    end

    it &quot;should fetch the second page of stories&quot; do
        VCR.use_cassette('reddit_programmer_humor_p2') do
            reddit.next.stories.count.should eq(25)
        end
    end
end
</code></pre>

<p>end
{% endcodeblock %}</p>

<p>And let&rsquo;s make the test pass:</p>

<p>{% codeblock Reddit API (Pass 3) - lib/reddit_api.rb lang:ruby %}
require &lsquo;json&rsquo;
require &lsquo;rest-client&rsquo;
require &lsquo;./lib/story&rsquo;</p>

<p>class RedditApi
    REDDIT_URL = &ldquo;<a href="http://reddit.com/r/&quot;">http://reddit.com/r/&quot;</a>
    attr_reader :url, :stories
    def initialize(subreddit)
        @subreddit = subreddit
        @after = &ldquo;&rdquo;
        @url = &ldquo;#{REDDIT_URL}#{subreddit}/.json?after=#{@after}&rdquo;
        request
        process_request
    end</p>

<pre><code>def next
    @url = &quot;#{REDDIT_URL}#{@subreddit}/.json?after=#{@after}&quot;
    request
    process_request
    self
end

def request
    @request_response = JSON.parse(RestClient.get(@url))
end

def process_request
    @stories = []
    @request_response['data']['children'].each do |red|
        d = red['data']
        @stories &lt;&lt; Story.new(d['title'], d['score'],
                              d['num_comments'], d['url'])
    end
    @after = @request_response['data']['after']
end
</code></pre>

<p>end
{% endcodeblock %}</p>

<p>We also allow method chaining since we return self after calling next (so you could chain next&rsquo;s for instance).</p>

<p>Another important principal to keep in mind is the &ldquo;Tell, Dont Ask&rdquo; rule. Without tests, we might have gone this route:</p>

<p>{% codeblock bad_example.rb lang:ruby %}
@reddit = Reddit.new(&lsquo;ProgrammerHumor&rsquo;)</p>

<h1 id="user-presses-next">User presses next</h1>

<p>@reddit.url = &ldquo;<a href="http://reddit.com/r/ProgrammerHumor/.json?after=sometoken&quot;">http://reddit.com/r/ProgrammerHumor/.json?after=sometoken&quot;</a>
{% endcodeblock %}</p>

<p>Not only would we not be telling the object what we want, we would be modifying the internal state of an object as well. By implementing a <code>next</code> method we abstract the idea of a URL and any tokens we may need to keep track of away from the consumer. Doing TDD adds a little extra step of &ldquo;Thinking&rdquo; more about what we want our interfaces to be. What&rsquo;s easier? Calling <code>next</code> or modifying the internal state?</p>

<p>I&rsquo;m kind of cheating a bit here. I found a nice &ldquo;table&rdquo; gem that outputs what you send in as a formatted table (think MySQL console output). Let&rsquo;s just make sure everything is being sent around properly and STDOUT is printing the correct contents:</p>

<p>{% codeblock Reddit CLI Spec (Pass 1) - spec/lib/reddit-cli.rb lang:ruby %}
require &lsquo;spec_helper&rsquo;
require &lsquo;stringio&rsquo;
require &lsquo;./lib/reddit-cli&rsquo;</p>

<p>describe RedditCli do
    let(:subreddit) { &ldquo;ProgrammerHumor&rdquo; }
    context &ldquo;#initializing&rdquo; do
        before(:all) do
            $stdout = @fakeout = StringIO.new
        end</p>

<pre><code>    it &quot;should print out a story&quot; do
        api_response = double(RedditApi)
        api_response.stub!(:stories =&gt;
                           [Story.new(&quot;StoryTitle&quot;, &quot;Score&quot;,
                                      &quot;Comments&quot;, &quot;URL&quot;)])
        $stdin.should_receive(:gets).and_return(&quot;q&quot;)
        cli = RedditCli.new(api_response)
        $stdout = STDOUT
        @fakeout.string.include?('StoryTitle').should be_true
    end
end
</code></pre>

<p>end
{% endcodeblock %}</p>

<p>We&rsquo;re doing several things here. First we&rsquo;re taking <code>$stdout</code> and putting it (temporarily) into a instance variable so we can see what gets outputted. Next we&rsquo;re mocking out the <code>RedditApi</code> since we dont actually need to hit that class or the VCR tapes, we just need to stub out the expected results (stories) and pass the response object along to the CLI class. And finally once we&rsquo;re finished we set <code>$stdout</code> back to the proper constant.</p>

<p>And the class for output:</p>

<p>{% codeblock Reddit CLI (Pass 1) - lib/reddit-cli.rb lang:ruby %}
require &lsquo;./lib/reddit_api&rsquo;
require &lsquo;terminal-table&rsquo;
class RedditCli
    def initialize(api)
        @rows = []
        @api = api
        @stories = api.stories
        print_stories
        print &ldquo;\nType ? for help\n&rdquo;
        prompt
    end</p>

<pre><code>def print_stories
    @stories.each_with_index {|x, i| @rows &lt;&lt; [i, x.score, x.comments, x.title[0..79] ] }
    puts Terminal::Table.new :headings=&gt; ['#', 'Score', 'Comments', 'Title'], :rows =&gt; @rows
end

def prompt
    print &quot;\n?&gt; &quot;
    input = STDIN.gets.chomp
    case input
    when &quot;?&quot;
        p &quot;Type the # of a story to open it in your browser&quot;
        p &quot;Type n to go to the next page&quot;
        prompt
    when &quot;quit&quot;, &quot;q&quot;
    when &quot;n&quot;
        @rows = []
        @stories = @api.next.stories
        print_stories
        prompt
    else
        print &quot;#=&gt; Oepning: #{@stories[input.to_i].url}&quot;
        `open #{@stories[input.to_i].url}`
        prompt
    end
end
</code></pre>

<p>end
{% endcodeblock %}</p>

<p>And finally, a little wrapper in the root directory:</p>

<p>{% codeblock Wrapper - reddit-cli.rb lang:ruby %}
require &lsquo;./lib/reddit_api&rsquo;
require &lsquo;./lib/reddit-cli&rsquo;</p>

<p>subreddit = ARGV[0]
RedditCli.new(RedditApi.new(subreddit))
{% endcodeblock %}</p>

<h2 id="an-important-note">An Important Note</h2>

<p>When working with external resources, whether it be a gem or a remote API, it&rsquo;s important to wrap those endpoints in your own abstraction. For instance, with our Reddit CLI we could have avoided those first 2 classes entirely, written everything in the CLI display class, and worked with the raw JSON. But what happens when Reddit changes their API? If this CLI class was huge or incoporated many other components, this could be quite a big code change. Instead, what we wrote encapsulates the API inside a <code>RedditApi</code> class that returns a generic <code>Story</code> struct we can work with and pass around. We don&rsquo;t care if the API changes in the CLI, or in any other code. If the API changes, we only have to update the one API class to mold the new API to the output we were already generating.</p>

<h2 id="end-result-amp-source-code">End Result  &amp; Source Code</h2>

<p><img src="https://img.skitch.com/20120821-bc2b49nued2e38tt3cekppeq1i.jpg"></p>

<p><center>
    <a href="https://github.com/bluescripts/reddit-cli">View Source on Github</a>
</center></p>
 </div>
    </article>
    
    <article class="post">
      <div class="date"> Aug 19, 2012 - 1 minutes</div>
      <h1 class="title"> <a href='https://joshrendek.com/2012/08/fixing-psych-syntaxerror-when-using-jekyll/'> Fixing Psych::SyntaxError when using Jekyll</a> </h1>
      <div class="content"> <p>I was working on my blog and moving some posts around when I kept getting a Psych::SyntaxError when generating it with Jekyll and ruby 1.9.x. Unfortunately the default stack trace doesn&rsquo;t provide much information on what file was causing the issue, so a quick way to find out is opening up irb:</p>

<p>{% codeblock Example to run in irb - sample.rb lang:ruby %}
require &lsquo;yaml&rsquo;
Dir.foreach(&ldquo;source/_posts&rdquo;).each {|f| YAML.load_file(&ldquo;source/_posts/&rdquo; + f) unless f == &ldquo;.&rdquo; || f == &ldquo;..&rdquo; }
{% endcodeblock %}</p>
 </div>
    </article>
    
    <article class="post">
      <div class="date"> Aug 19, 2012 - 1 minutes</div>
      <h1 class="title"> <a href='https://joshrendek.com/2012/08/moved-domains-to-my-name/'> Moved domains to my name</a> </h1>
      <div class="content"> <p>Moved everything over to my other domain, joshrendek.com incase you&rsquo;re wondering why you got redirected.</p>
 </div>
    </article>
    
  </div>

  <div class="sidebar">
  <section>
    <h1>Projects & Software</h1>
    <ul>
      <li><a href="https://github.com/joshrendek/docker-conductor">Docker Conductor</a> is a docker orchestration tool.</li>
      <li><a href="http://sshpot.com/">sshpot.com</a> is a SSH honeypot service written in Go (both web service and client are open source).</li>
      <li><a href="http://ifcfg.net/">ifcfg.net</a> is a simple 'what is my IP' service with a few extra RESTful endpoints.</li>

      <li><a href="/projects/">View More</a>

      <li><a href="https://github.com/joshrendek?tab=repositories"><img src="/images/github.png" style='border: none;'> More on GitHub</a></li>
      <li><a href="https://rubygems.org/profiles/joshrendek">Gems @ RubyGems</a></li>
    </ul>
  </section>

  <section>
    <h1>Other Blogs</h1>
    <ul>
      <li><a href="http://tendermeatlove.com">Tender Meat Love</a> is my blog about cooking.</li>
      <li><a href="http://hydronerd.com">Hydro Nerd</a> is my blog about hydroponics and gardening.</li>
    </ul>
  </section>

  <section>
    <h1>Recent Posts</h1>
    <ul>
      
      <li><a href="https://joshrendek.com/2016/06/building-honeypots-and-analyzing-linux-malware/">Building honeypots and analyzing linux malware</a></li>
      
      <li><a href="https://joshrendek.com/2015/11/understanding-elasticsearch-performance/">Understanding ElasticSearch Performance</a></li>
      
      <li><a href="https://joshrendek.com/2015/11/building-a-distributed-waitgroup-with-go-and-redis/">Building a distributed WaitGroup with Go and Redis</a></li>
      
      <li><a href="https://joshrendek.com/2015/11/docker-and-ping-sendmsg-operation-not-permitted/">Docker and ping: sendmsg: Operation not permitted</a></li>
      
      <li><a href="https://joshrendek.com/2015/10/influx-alert/">Influx Alert</a></li>
      
    </ul>
  </section>

</div>

</main>

<div class="page-nav">
  <div class="page-prev">
    
        <a href="/page/2/" title="Previous page" > &lt;&lt; </a>
    
  </div>

  <div class="page-num">
    3/12
  </div>

  <div class="page-next">
    
    <a href="/page/4/" title="Next page"> >> </a>
    
  </div>
</div> 


  <footer>

  <div class="social-links-footer">

  

  

  

  

  

  <div class="social-link">
  <a href="https://joshrendek.com/index.xml" target="_blank">RSS</a>
  </div>

</div>


  <div class="copyright"> © Copyright 2008-2017 Josh Rendek </div>

  </footer>

</body>
</html>

